# 職務経歴書

## 基本情報

| key             | value                                       |
| --------------- | ------------------------------------------- |
| Name            | 内藤翔太（Shota Naito）                     |
| BirthDay        | 1999 年 3 月 9 日                           |
| Final Education | 慶應義塾大学大学院理工学研究科              |
| Zenn            | https://zenn.dev/mbao                       |

---

## スキル

---

## 技術スタック

### 言語・フレームワーク

[![My Skills](https://skillicons.dev/icons?i=js,ts,react,next,tailwind,php,laravel,py,nest,prisma,graphql)](https://skillicons.dev)

### その他

[![My Skills](https://skillicons.dev/icons?i=aws,terraform,linux,docker,mysql,postgres,pnpm,githubactions,git,github,figma)](https://skillicons.dev)

---

## 保有資格

- Microsoft Office Specialist Word 2016, Excel 2016, PowerPoint 2016 (2017/10)
- TOEIC Listening & Reading Test 835 点 (2020/11)
- 基本情報技術者試験 (2022/11)
- AWS Certified Solutions Architect - Associate (2023/08)
- 応用情報技術者試験 (2023/11)

---

## 職務経歴詳細（社会人）

### レバレジーズ株式会社（2023/04〜）

#### レバテックプラットフォーム認証・認可基盤リプレース（2024/07〜2024/10）

■ プロジェクト概要

- 既存システムから新システムへの認証・認可機能のリプレースを担当しました

■ 技術スタック

- Next.js、TypeScript、NestJS、AWS (ALB)、OIDC、JWT、Redis

■ チーム情報

- 4〜5 名

■ 担当業務と力を入れた部分

- 認証・認可基盤のリプレース
  - 担当
    - フロントエンド、バックエンド、アーキテクチャ設計
  - 課題・問題点
    - 既存システムの Redis をセッション代わりに使用しており、新システムへの移行時に既存サービスとの不整合やセキュリティリスクを防ぐ必要がありました
    - チーム内で OIDC や認可制御（RBAC / PBAC）の知識が不足していました
  - 打ち手・使用した技術
    - チームの知識不足を補うため、OIDC と認可制御（RBAC / PBAC）の勉強会を設計・実施しました。OIDC では「[OAuth、OAuth 認証、OpenID Connect の違いを整理して理解できる本](https://techbookfest.org/product/4885634867003392?productVariantID=6565720896831488)」を使用し、RBAC / PBAC では議論を通じてハイブリッド形式が最適との結論に達し、チーム内で共通認識を形成しました
    - 各サービスから Redis に対して行っているセッション情報の読み書き処理をすべて調査し、既存システムとの不整合を避けながら移行できるよう設計しました
    - 認証基盤移行後、認証基盤による障害は 0 件で、安定したシステム運用を実現しました

#### レバテックプラットフォーム不要コード削除（2024/10〜2024/11）

■ プロジェクト概要

- リプレースを迅速かつ安全に進めるための不要コード削除を主導しました

■ 技術スタック

- CloudWatch Logs Insight、Python

■ チーム情報

- 1 名

■ 担当業務と力を入れた部分

- 不要コード削除の推進
  - 担当
    - バックエンド、技術調査
  - 課題・問題点
    - 不要コードが残ることでセキュリティリスクの発生する懸念がありました
    - リプレース対象の仕様を把握し、置き換え対象を明確にする必要がありました
  - 打ち手・使用した技術
    - CloudWatch Logs Insight で正規表現を用いてアクセスパスを抽出し、ルーティング定義と照合することで削除対象を特定しました。Apache ログに記録されない PHP アプリケーション内部での処理を見逃さないよう、最終確認用のログを仕込み安全性を担保しました
    - 不要コード削除の手順を明確化し、タスクとして誰でも対応できる状態を整備しました。結果として 1 か月で約 30 本の API / 1,500 行のコードを削除し、セキュリティリスクを低減しました

#### レバテックプラットフォーム各機能のリプレース（2025/01〜2025/06）

■ プロジェクト概要

- リプレースにおける開発品質の向上とチーム開発プロセスの改善を推進しました
- 内部品質と外部品質の向上を目指し、各機能のリプレースを担当しました

■ 技術スタック

- Git、GitHub、ESLint、Docker、Terraform、TypeScript、PHP、Prisma、Next.js、Figma、Volt（デザインシステム）、AWS (ECS / CloudWatch)、NewRelic

■ チーム情報

- 3〜5 名

■ 担当業務と力を入れた部分

- 各機能のリプレース実装
  - 担当
    - バックエンド、フロントエンド、品質管理、意思決定
  - 課題・問題点
    - 既存システムに不適切なバリデーションや文字化けの問題がありました
    - リプレース後の仕様について、チーム全体で合意形成する必要がありました
    - データ移行を安全に実施する必要がありました
    - 新しい技術スタック（Volt（社内デザインシステム）、Figma Dev Mode）を使用する初めての取り組みでした
  - 打ち手・使用した技術
    - 既存システムの外部仕様調査を通じて不適切なバリデーションを特定し、最適化の提案と実装を進めました。入力可能文字の網羅的なテストを実施し、文字化けする問題を特定して解決しました
    - 既存仕様の詳細な調査と改善点の整理を実施し、テックリードとの対話を通じて新たな視点を取り入れました。ディレクターや開発メンバーとの議論の場を設け、チーム全体の意見を反映させながらリプレース後の仕様を確定させました
    - データ移行を 7 段階の手順に分解し、並行運用基盤を構築した後、厳密なデータ整合性検証と段階的な参照切り替えを組み合わせることで、ユーザ影響を完全に排除する移行手順を確立しました。最終的に障害ゼロでの移行を達成しました
    - Volt や Figma の Dev Mode を使った開発が初めてだったため、管理チームに相談し必要な知識を収集しました。チーム内で実装手順や設計方針の認識を統一するためにモブプログラミングを実施しました

- プロセス改善と品質管理
  - 担当
    - プロセス改善、品質管理、コードレビュー
  - 課題・問題点
    - 複数チームが触る複数のリポジトリで Git 運用ルールが策定されておらず、想定外の修正が本番環境にデプロイされるリスクがありました
    - 環境構築手順が複数存在し、各チームで異なる環境を使用しており、環境変数設定ファイルが散らかり秘匿情報の誤公開リスクがありました
    - リプレースにあたり、共通認識化のためのコミュニケーションコストと作業の属人化が課題でした
  - 打ち手・使用した技術
    - Git 運用ルールをゼロから作成・提案し、複数の選択肢のメリット・デメリットや実現可能性を整理しました。3 チームが一堂に会する場を設け意見を収集して全員が納得できる形で確定し、フロー図として可視化しルールを明記しました
    - 環境構築手順を統一し、環境変数設定ファイルの責務を明確化することで、各チームが同じ環境で開発できる体制を整えました
    - モブプログラミングを導入し、ドライバー、ナビゲーター、サポーターの役割の明確化と 15 分での交代制、振り返りの導入、Todo リストの作成などをルール化しました

- 運用改善
  - 担当
    - インフラ、DevOps
  - 課題・問題点
    - 現システムのログ情報不足により運用負荷が高い状態でした
    - リリース後に継続的に運用できる持続可能性を担保する必要がありました
    - ECS の夜間停止設定がされておらず、無駄なリソース消費が発生していました
    - CI/CD の実行時間が長く、開発効率が低下していました
  - 打ち手・使用した技術
    - ログ設計指針を策定し、「担当者識別情報」「ユーザーへの影響」「即時対応の必要性」を出力するよう変更しました。AsyncLocalStorage を活用してリクエストごとのコンテキスト情報を保持することで、エラー発生ユーザを迅速に特定できるようにしました
    - 担当チームのダッシュボードを 0→1 で作成し、認証や各機能に特化したダッシュボードを複数作成しました。メトリクスを見る会の設計により継続的に監視できる体制を整え、メモリや CPU 使用率の閾値を設定して Slack へのアラートを設定することで、システムの安定稼働を実現しました
    - STG 環境と DEV 環境で ECS の夜間停止設定を実施し、無駄なリソース消費を抑えました
    - ECR リモートキャッシュを導入し、CI/CD の実行時間を短縮しました

#### レバテックプラットフォームインフラ構築（2024/07〜2025/06）

■ プロジェクト概要

- リプレースに伴うインフラ構築を担当しました

■ 技術スタック

- Terraform、AWS (ECS / ALB / NLB / VPC / CloudWatch / Route53 / Secrets Manager)

■ チーム情報

- 1 名

■ 担当業務と力を入れた部分

- インフラ構築
  - 担当
    - インフラ
  - 課題・問題点
    - リプレースに伴い、新規インフラ構築が必要でした
    - Terraform で構築した ECS へのアクセスに失敗する問題が発生しました
  - 打ち手・使用した技術
    - Terraform で ECS、ALB、NLB、VPC、CloudWatch、CloudTrail を構築しました
    - VPC のルーティングテーブル、NLB と ECS のセキュリティグループ、NLB のターゲットグループ、ECS のコンテナ公開ポートを順に検証し、NLB のターゲットグループ設定にトラフィック転送先ポートの誤りを発見し、問題を解決しました
#### TiDB 移行プロジェクト（2024/05〜2024/06）

■ プロジェクト概要

- レバテックでもっとも歴史があり最大容量の DB を Amazon RDS から TiDB へ移行
- AWS Database Migration Service を使用したフルロードと継続的レプリケーション

■ チーム情報

- 4 名

■ 担当業務と力を入れた部分

- データ移行時の障害対応と復旧
  - 概要
    - TiDB 移行時に発生した複数の障害の原因調査と復旧を担当しました
    - 参考：[Amazon RDS から TiDB 移行時のしくじり集](https://zenn.dev/levtech/articles/bc0786a0c7c849)
  - 技術スタック
    - TiDB、MySQL、AWS DMS、Python、Shell Script
  - 担当
    - データベース、障害対応
  - 課題・問題点
    - TiDB の AUTO_INCREMENT のキャッシュが更新されず、Duplicate Key Error が発生しました
    - TIMESTAMP 型のデータに 9 時間のずれが発生しました
    - NO_ZERO_DATE の影響で移行できていないデータが存在しました
    - BLOB 型のデータが 32KiB までしか連携されていませんでした
    - 全角検索のヒットしなくなる問題が発生しました
  - 打ち手・使用した技術
    - AUTO_INCREMENT の問題について、TiDB の各ノードが異なる採番帯を持つ仕組みを調査し、`ALTER TABLE` による採番キャッシュのリセットで全テーブルの問題を解消しました
    - TIMESTAMP のずれについて、全テーブルを調査してリペアが必要なテーブルとカラムを特定しました。約 300 万件の膨大なデータに対して、手動リペアは不可能と判断し、バッチ処理での自動更新スクリプトを作成して問題なく完遂しました
    - NO_ZERO_DATE の問題について、awsdms_apply_exceptions から INSERT や UPDATE が失敗しているデータを確認し、データリペアを実施しました
    - BLOB 型の問題について、移行元 DB からダンプファイルを取得し、Blob→Hex 変換後に移行先 DB へ取り込み、UPDATE 文でデータを復旧しました
    - 全角検索の問題について、Collation が誤って変更されていることを特定し、`utf8mb4_unicode_ci` に修正して解決しました
    - 対応の遅れによるユーザーのログイン不可と離脱を防ぐため、すべての障害対応をその日中に完了し、ユーザー影響を最小限に抑えました

- 組織への知見共有と再発防止
  - 概要
    - TiDB 移行の失敗経験を組織全体の資産として共有しました
  - 課題・問題点
    - 他チームも TiDB 移行を控えており、同様の障害発生リスクがありました
  - 打ち手・使用した技術
    - 社内 LT で TiDB 移行時のしくじりと教訓を発表しました
    - 他チームが移行時に確認すべき項目を明確にし、CTO や SRE チームと連携しながら TiDB 移行チェックシートを作成しました
    - チームメンバーに TiDB の AUTO_INCREMENT の仕組み（各ノードで異なる採番帯を持つ）を説明し、問題解決をサポートしました

#### レバテックプラットフォーム開発・運用（2023/11〜2024/06）

■ プロジェクト概要

- レバテックプラットフォーム (https://platform.levtech.jp/) の開発・運用
- レバテックフリーランスに登録した IT エンジニアやクリエイターが利用できる専用マイページ・Web サービス
- 高単価案件の検索、企業からのスカウト受け取り、市場価値の診断、契約・請求事務処理の一元管理などをオンライン上で完結するマッチング・支援ツール

■ チーム情報

- 5〜6 名

■ 担当業務と力を入れた部分

- 重複 CV 改善施策の設計・実装
  - 概要
    - 重複した候補者データを防止する機能をゼロから設計・実装しました
  - 技術スタック
    - NestJS、TypeScript、Prisma、AWS (EventBridge)、DDD
  - 担当
    - バックエンド、アーキテクチャ設計
  - 課題・問題点
    - 新規機能のため、アーキテクチャや技術選定から検討する必要がありました
    - 将来の機能拡張を見据えた拡張性の高い設計が求められました
    - 複数システム（LTID、オウンド）との連携が必要で、システム間の接点設計が必要でした
  - 打ち手・使用した技術
    - AWS EventBridge を使用したイベント駆動アーキテクチャを採用し、システム間の疎結合を実現しました
    - DDD（ドメイン駆動設計）と DIP（依存性逆転の原則）を採用し、ドメイン層とインフラ層に分割することで各層の責務を明確にし、システムの拡張性と保守性を高めました
    - LTID チーム（認証基盤）やオウンドチーム（外部サイト連携）との接点を整理し、EventBridge デプロイ時のパラメータ連携を事前に依頼することで、デプロイと動作確認をスムーズに実施しました

- セキュリティ対応と品質保証
  - 概要
    - セキュリティホールの調査・修正と品質保証活動を担当しました
  - 技術スタック
    - NestJS、TypeScript、CloudWatch、DAST
  - 担当
    - バックエンド、セキュリティ
  - 課題・問題点
    - 認可処理に脆弱性が発見されました
    - toB 画面での DAST 実行が長期間実行されておらず、セキュリティ品質の担保が必要でした
  - 打ち手・使用した技術
    - ローカル環境と STG 環境で段階的に検証し、認可処理の脆弱性を特定・修正しました
    - toB 画面でウェブアプリケーションスキャンを設定・実行し、セキュリティ品質を担保しました
    - 対応後、CloudWatch でアプリケーションログを分析し、対応の妥当性を検証しました

- 業務自動化と効率化
  - 概要
    - 経理部門や営業部門の業務効率化のための自動化を実施しました
  - 技術スタック
    - TypeScript、BigQuery、Google Sheets、Python
  - 担当
    - バックエンド、自動化
  - 課題・問題点
    - 経理から PDF 請求書のテキストコピー権限付与の依頼がありましたが、実際のニーズが不明確でした
    - 月次での案件検索条件のデータ集計を手動で行っており、ミスのリスクがありました
    - 案件評判 CSV データ確認作業で目視チェックが発生しており、データ不備のリスクがありました
  - 打ち手・使用した技術
    - 経理へのヒアリングで実際のニーズが請求書情報の一覧であることを把握し、BigQuery から自動取得して Google Sheets に出力する仕組みを構築しました
    - 月次データ集計を BigQuery と Google Sheets 間で自動化し、手作業によるミスのリスクを排除しました
    - 案件評判 CSV データ確認作業をスクリプトで自動化し、目視チェックを不要にしました

- チーム開発プロセスの改善
  - 概要
    - ドキュメント管理の体系化と運用プロセスの効率化を推進しました
  - 課題・問題点
    - ドキュメントの散在により情報の検索性とメンテナンス性が低下していました
    - 営業からの問い合わせ対応が属人化しており、ナレッジの蓄積ができていませんでした
    - 技術ドキュメントの更新が属人的で、メンテナンスが漏れる状態でした
  - 打ち手・使用した技術
    - ドキュメント管理方針を策定し、GitHub を中心としたバージョン管理体制を構築しました。ドキュメントオーナー制度を導入し、継続的なメンテナンスを実現しました
    - 問い合わせ対応フローを整備し、対応履歴の可視化とナレッジ蓄積を実現しました
    - 技術ドキュメントの自動生成・更新を CI/CD パイプラインに組み込み、更新漏れを防止しました

- インフラとモニタリングの改善
  - 概要
    - IaC の運用改善とモニタリング体制の強化を推進しました
    - 参考：[我々はまだ知らなかった。NewRelic の真の姿を](https://zenn.dev/levtech/articles/newrelic-less-known-features)
  - 技術スタック
    - Terraform、AWS、NewRelic、Autify
  - 担当
    - インフラ、DevOps
  - 課題・問題点
    - AWS リソースの上限管理が適切に行われておらず、E2E テスト環境の拡張に支障が出ていました
    - Terraform による IaC と実環境の差分が発生し、運用の信頼性が低下していました
    - 他チームが利用する共通モジュールでの設定ミスを防ぐ仕組みが不足していました
  - 打ち手・使用した技術
    - AWS Service Quotas の調査と SRE チームとの連携により、リソース上限を最適化しました
    - Terraform の公式ドキュメントと技術記事を参照し、IaC と実環境の差分を適切に管理する運用方針を確立しました
    - 共通モジュールにバリデーション機能を実装し、設定ミスの早期検出とエラーメッセージによるガイダンスを実現しました
    - 外部勉強会で NewRelic の新機能を学習し、外形監視（Synthetic Monitoring）を導入してシステムの可観測性を向上させました

#### 新卒研修期間（2023/04〜2023/10）

■ 研修概要

- クイズアプリ開発、ATS（採用管理システム）開発を通じた実践的な研修

■ チーム情報

- 新卒 4 名

■ 研修内容と力を入れた部分

- クイズアプリ開発（15 営業日）
  - 概要
    - システム本部キックオフ向けのクイズアプリを開発しました
  - 技術スタック
    - Next.js、TypeScript、Prisma、Socket.IO、AWS、Terraform
  - 担当
    - インフラ、バックエンド、フロントエンド
  - 課題・問題点
    - チームメンバーが実装に慣れておらず、進捗が予定より遅れていました
    - 開発期間が 15 営業日と短く、タスクの優先順位付けが重要でした
  - 打ち手・使用した技術
    - Socket.IO を使用したリアルタイム通信機能を実装し、複数チームが同時参加できるクイズシステムを構築しました
    - インフラ関連のタスクが他のタスクのブロッカーになっていることに気づき、自身の開発タスクを一時停止してインフラ環境構築を優先的に進め、チーム全体の開発を円滑化しました

- ATS 開発での設計リードと品質向上（3 ヶ月）
  - 概要
    - 人事部向けの採用管理システムの設計と開発をリードしました
  - 技術スタック
    - Remix、TypeScript、NestJS、Prisma、AWS、Terraform
  - 担当
    - インフラ、バックエンド、アーキテクチャ設計
  - 課題・問題点
    - チーム内でバックエンド設計の知識が不足しており、実装方法のバラツキと保守性の低下が懸念されました
    - 既存システムの仕様をそのまま実装すると、データモデルの複雑化による保守性低下の懸念がありました
  - 打ち手・使用した技術
    - モジュラモノリス勉強会への参加と技術メンターとの設計議論を通じて、NestJS + Prisma を用いたレイヤードアーキテクチャを設計しました。ディレクトリ構成と各ファイルの責務を明確に定義し、外部設計と内部設計の目的とアウトプット物を整理することで、チーム全体の設計認識を統一しました
    - 既存システムの仕様を鵜呑みにせず、実際の採用プロセスを基に UI とデータモデルを再設計し、コードの複雑性を低減させました

- チームメンバーの技術サポートと育成
  - 概要
    - チームメンバーの技術的な課題解決をサポートし、自走できるレベルまでの成長を支援しました
  - 課題・問題点
    - チームメンバーが NestJS、Prisma などの技術に不慣れで、開発の滞る場面がありました
    - チームメンバーの実装が進まず、知識を伝えるだけでは自走できるレベルまで理解が深まらない状況でした
  - 打ち手・使用した技術
    - NestJS と Prisma のキャッチアップ用リポジトリを作成し、PostgreSQL の Docker 環境、Prisma のスキーマ定義と使用法、NestJS のリポジトリ構成・API 実装、Swagger の使用法などを整備しました。後日、このリポジトリを基にペアプログラミングを実施し、チームメンバーのキャッチアップをサポートしました
    - 知識を伝えるだけでは不十分と判断し、質問を交えてチームメンバーが自ら考える時間を増やすコーチング手法に切り替え、実践的な理解を深めるよう支援しました

- プロジェクト管理の改善
  - 概要
    - プロジェクトの開発手法を顧客ニーズに合わせて最適化しました
  - 課題・問題点
    - ウォーターフォール型の開発手法では、顧客の負担が増大し、変更要望への柔軟な対応が困難でした
  - 打ち手・使用した技術
    - 顧客満足度を最優先に考え、開発手法をアジャイル型に切り替えました。ただし、リプレイスプロジェクトで要件が確定していることを考慮し、要件定義と設計は事前に完了させ、開発フェーズのみをユーザーストーリー単位で反復的に進めるハイブリッド型アプローチを採用しました

## インターン経歴詳細（大学院在籍時）

### レバレジーズ株式会社（2022/04〜2023/03）

■ 稼働ペース

- 平均週 2 日（実働 16〜20 時間）

■ プロジェクト概要

- 新卒採用向け動画面接サービス

■ 業務概要

- 新卒採用向け動画面接サービスの設計〜バックエンド開発、インフラ環境移行

■ チーム情報

- 4〜6 名

■ 業務内容と力を入れた部分

- 要件定義〜仕様決定
  - 概要
    - 新卒採用向け動画面接サービスの要件定義から仕様決定までのプロセスを担当しました
  - 課題・問題点
    - 決定した仕様は仕様書にまとめていたものの、仕様決定の背景が整理されておらずチーム内で仕様決定の背景を確認する議論が繰り返されていました
  - 打ち手・使用した技術
    - 仕様決定時に考慮事項と決定背景をまとめるようチームに促し、不要な議論の時間を削減しました

- Laravel での API 開発
  - 概要
    - Laravel を用いたサーバーサイドの設計・実装（API）
  - 技術スタック
    - Laravel、PHP、MySQL、Amazon SES、Laravel Sanctum
  - 担当
    - バックエンド
  - 課題・問題点
    - Laravel に初めて触れるメンバーが多かったため、習得の負担を軽減する必要がありました
    - 上記の背景とリリースの時期の観点から、自分が比較的重ための機能を実装する必要がありました
  - 打ち手・使用した技術
    - 小規模システムで Laravel 初学者がいることを考慮し、キャッチアップをほぼ必要とせず責務を分けて実装できる MVCS 構成を採用しました
    - 脆弱性（CSRF, XSS）対策の容易性と SPA への拡張を考え、Laravel Sanctum による SPA 認証を採用しました
    - AWS サービスとの統合と無料枠内のメール数を重視し、Amazon AWS SDK for PHP × Amazon SES でメール機能を実装しました。メール送信に必須の SPF と DKIM を整備し、バウンス率を低く抑えました

- AWS の環境移行
  - 概要
    - AWS アカウント間でのインフラ環境移行を最小ダウンタイムで実現しました
  - 技術スタック
    - AWS (Route53, VPC, EC2, RDS)
    - AWS (S3, Lambda, Secrets Manager, CloudWatch)
    - systemd、nginx、Shell Script
  - 担当
    - インフラ
  - 課題・問題点
    - 会社の都合で AWS アカウント間のインフラ環境移行が必要でしたが、サービスへの影響を最小限に抑える必要がありました
    - チーム全体でインフラに関する知識が不足しており、ゼロから学習する必要がありました
  - 打ち手・使用した技術
    - 手作業による冪等性の低下を防ぐため、各種コマンドをシェルスクリプト化しました。EC2、RDS、S3 の段階的移行戦略を立案し、本番環境では php-fpm の再起動と RDS のロック約 15 秒のダウンタイムで移行を実現しました
    - Route53、VPC、EC2、RDS、S3、Lambda、Secrets Manager、CloudWatch などの AWS リソース、systemd、nginx、SSH ポートフォワードなどの技術を習得し実践に活用しました

- チーム開発体制の改善
  - 概要
    - チーム内のコミュニケーションと開発体制の改善を推進しました
  - 課題・問題点
    - 作業の進捗や課題の共有が不十分であり、チームの協働効率が低下していました
    - 心理的安全性の不足により、質問や相談のしづらい雰囲気がありました
    - 新メンバーのオンボーディングプロセスが整備されておらず、立ち上がりに時間がかかっていました
  - 打ち手・使用した技術
    - 分報を導入し、作業の進捗と課題を可視化しました。これにより課題解決のスピードが向上し、心理的安全性が担保された空間づくりに成功しました
    - 1 日 15 分の学びシェアの会を企画し、チーム全体の学習意欲向上とナレッジ共有を促進しました
    - 参照ドキュメントと環境構築手順を整備し、分報による進捗把握と適宜サポート体制を構築することで、新規メンバーのオンボーディング期間を短縮しました

### ソーシャルデータバンク株式会社（2022/09〜2023/03）

■ 稼働ペース

- 平均週 2 日（実働 16〜20 時間）

■ プロジェクト概要

- LINE 公式アカウントの配信・運用・管理サポートサービス Liny の開発
- エンジニアのパフォーマンス測定・改善（DevOps）

■ 業務概要

- LINE 公式アカウントの配信・運用・管理サポートサービス Liny の開発とエンジニアのパフォーマンス測定・改善（DevOps）

■ チーム情報

- 20 名ほど
- 2 名

■ 業務内容と力を入れた部分

- API パフォーマンスの最適化
  - 概要
    - API の通信量と応答速度の大幅な改善を実現しました
  - 技術スタック
    - Laravel、PHP
  - 担当
    - バックエンド
  - 課題・問題点
    - API のレスポンスサイズが大きく、応答速度が遅いことでユーザー体験が低下していました
  - 打ち手・使用した技術
    - 必要なデータの洗い出しとボトルネックの特定により、レスポンスサイズを 52％削減（2.3MB → 1.1MB）、応答時間を 68％短縮（4.11s → 1.31s）しました。デプロイ後もリグレッションは発生せず、安定した改善を実現しました

- フロントエンド技術スタックの刷新
  - 概要
    - レガシー化したフロントエンド環境を最新技術スタックへ移行する基盤を整備しました
  - 技術スタック
    - Vue2 → Vue3、webpack → Vite
  - 担当
    - フロントエンド
  - 課題・問題点
    - Vue2 のサポート終了に伴う未更新パッケージの増加と、長いビルド時間による開発者体験の低下が課題でした
  - 打ち手・使用した技術
    - Vue3 と Vite への移行環境を整備し、レガシーパッケージからの脱却とビルド時間の大幅な短縮により、開発者体験を向上させました

- 開発生産性の可視化と改善
  - 概要
    - エンジニアチームの開発生産性を測定・可視化し、組織全体の改善を推進しました
  - 技術スタック
    - TypeScript、GitHub Actions、Notion DB、Google Sheets
  - 担当
    - DevOps
  - 課題・問題点
    - 開発プロセスのパフォーマンスが可視化されておらず、ボトルネックの特定や改善施策の効果測定が困難でした
  - 打ち手・使用した技術
    - GitHub Actions、Notion DB、Google Sheets を活用し、変更のリードタイム（PR 作成からマージまでの時間）を自動測定する仕組みを構築しました。運用コストゼロで継続的な測定を実現しました
    - 個人別・プロジェクト別のメトリクスを各チームに展開し、毎週の振り返りで改善施策を推進しました。その結果、全チームでリードタイムを削減しました
